# Generating Data

In order for mock services to be effective, they need to be populated with data. 

> Many service mocks simply return data in JSON format in response to a query.

Some, very few, rules apply to all service methods; others, also view, apply to methods for a given type of service.

All services respond with JSON.

JSON-RPC 1.1 and JSON-RPC 2.0 services respond with their respective JSON-RPC container objects, with specific rules pertaining to them, and our practices applied on top. An overview of those services is provided in separate documents.

Some considerations for the data needs of service methods:

- many have a single 1-1 relationship between a given set of parameters and a given data object; they are deterministic.
- some are similar in that there is a 1-1 relationship, but the result is not deterministic (e.g. the current time may be provided)
- some query a collection and return a set of similar data items; supporting ad-hoc queries for this type of method requires more complex mock implementations.
- some have dependencies on other service methods; e.g. authentication
- some have data dependencies which may be required by the code being tested (that is, the test code which is using this mock service); e.g. a username may also required that the user profile for that username be available.

When generating data, we need to think holistically. Since our services essentially form a loosely coupled "database", or data system, we
generally need to provide a set of data for mock services which satisfy all service and data dependencies.

For instance, a workspace object may reference other objects, users, samples, apps, etc. If we mock a workspace object,
we probably need to mock the user profile, samples, sample acls, app specs, and so forth.

## How to generate data

Data may be generated by hand or by script. Scripting is preferable, but implies that the appropriate data is available in a KBase deployment environment such as CI. (Ideally we would have a testing environment with well established, stable data sets; we've discussed this for years but have yet to implement it. For now, CI is our best bet.)

Generating data by hand is both difficult, unreliable, and very hard to replicate, but may be necessary. For instance, the mocks may limit test the system with data which would not be allowed into production; or the services may not be available at the time.

### Generating Data by Script

A data generation script should be created for each service. This script (or set of scripts) should contains both a standalone command-line and library interface. The command line interface is handy for fetching data ad-hoc, and for developing the script. The library interface allows composition of multiple service data fetching procedures into a single script which may generate the data for a given project, fetching data from many services.

## Storage

As mentioned above, all mock data for a given mock server runtime must be stored in a single directory, with data for a given service stored in a sub-directory named with the service module identifier. If there is no service identifier, the service directory name can be the common name of the service (e.g. the directory path used for the kbase proxy), or otherwise a name established by the mock service and documented therein.

E.g. the data for the workspace (JSON-RPC 1.1, service module "Workspace") may be stored in:

```bash
data/Workspace
```

for auth (REST, no service module) as:

```bash
data/Auth
```

for the sample service (JSON-RPC 2.0, no service module) as

```bash
data/sample_service
```

### Common Patterns

#### File Names

A common pattern for many services is to store data like:

```text
entitytype_ID.json
```

e.g.

```text
sample_5cdb2854-b194-4644-a4c6-6ff2ed24b9c8-1.json
```

where `sample_` is used as the prefix for this type of object, `5cdb2854-b194-4644-a4c6-6ff2ed24b9c8-1` is the full
sample identifier, with a `-` separating the sample id and the sample version.

Note that we want the `ID` to be an unambiguous, complete identifier. Each service will have a different way of forming
this. We do not want relative references which lack a version, if the object type is versioned. To mock fetching a
versioned resource without a version, all versions should be present and the service mock code should implement
the correct behavior, which is typically to return the most recent version. It may accomplish this by fetching a directory listing of all objects with the same basic id, and select the one with the most recent version. It is also acceptable to create a duplicate object file of the most recent object, but without the version appended.

Another example

```text
object_62462-29-1.json
```

#### File format

As each service responds with JSON, all data files should be in JSON format. One exception may be hand-generated files, which could be in YAML.

Format of the file should be the original JSON-RPC `result` (or `error`, but that is to be worked on still). For certain
REST services without a JSON-RPC wrapper structure, the plain response can be stored.

The reasons to use the result rather than the entire response objects:

- the JSON-RPC protocol requires matching the id of request with response
- the wrapper does not change, other than id, from request to request
- bulk/batch/collection methods return multiple result items in an array; each item should be stored and the service
  mock should collect them together into the result array.

## Management

Generated data must not be checked into the repo.

Rather, if you wish to be able to incorporate a specific case of test data in to repo, check in a ... ??

## Examples

```bash
export TOKEN="MYTOKEN"
export REF="wsid/objid/ver"
deno run --unstable --allow-write --allow-read --allow-net --import-map=import_map.jsonsrc/cli/fetchSampleSet.ts --ref "$REF" --token "$TOKEN" --dest out

```

## TODO

- mocking errors?
